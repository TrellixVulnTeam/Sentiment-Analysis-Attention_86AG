{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a12c21-dfb9-4511-b6c2-b69c4bc75cac",
   "metadata": {},
   "source": [
    "**Tuning Hyper-Parameters**<br/>\n",
    "In this notebook we will find the optimal hyper-parameters by training our model and checking the validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8680f53-97b4-4cab-bd5a-972f648420aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "import json\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "warnings.simplefilter(\"ignore\")\n",
    "plt.rcParams['font.size'] = 20\n",
    "data_dir = os.path.expanduser('~/.pytorch-datasets')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#loading our models\n",
    "from project.Trainer import train_and_eval\n",
    "from project.RNN import SentimentAnalyzer\n",
    "from project.Attention import AttentionAnalyzer\n",
    "\n",
    "#loading the dataset\n",
    "import torchtext.data\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "\n",
    "review_parser = torchtext.data.Field(\n",
    "    sequential=True, use_vocab=True, lower=True,\n",
    "    init_token='<sos>', eos_token='<eos>', dtype=torch.long,\n",
    "    tokenize='spacy', tokenizer_language='en_core_web_sm'\n",
    ")\n",
    "\n",
    "# This Field object converts the text labels into numeric values (0,1,2)\n",
    "label_parser = torchtext.data.Field(\n",
    "    is_target=True, sequential=False, unk_token=None, use_vocab=True\n",
    ")\n",
    "import torchtext.datasets\n",
    "\n",
    "ds_train, ds_valid, ds_test = torchtext.datasets.SST.splits(\n",
    "    review_parser, label_parser, root=data_dir,fine_grained=False\n",
    ")\n",
    "#building vocabulary and loading GloVe 6B pretrained embeddings\n",
    "review_parser.build_vocab(ds_train,vectors=GloVe(name='6B', dim=300))\n",
    "label_parser.build_vocab(ds_train)\n",
    "word_embeddings = review_parser.vocab.vectors\n",
    "word_embeddings = word_embeddings.to(device=device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c48f7b4-9b2e-4cc3-b8a8-11bcc24ab239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(batch_size):\n",
    "    BATCH_SIZE = batch_size #hyper parameter, could be changed\n",
    "\n",
    "    # BucketIterator creates batches with samples of similar length\n",
    "    # to minimize the number of <pad> tokens in the batch.\n",
    "    dl_train, dl_valid, dl_test = torchtext.data.BucketIterator.splits(\n",
    "        (ds_train, ds_valid, ds_test), batch_size=BATCH_SIZE,\n",
    "        shuffle=True, device=device)\n",
    "\n",
    "    train_iter, valid_iter, test_iter = torchtext.data.BucketIterator.splits((ds_train, ds_valid, ds_test), batch_size=BATCH_SIZE, sort_key=lambda x: len(x.text), repeat=False, shuffle=True)\n",
    "    return train_iter, valid_iter, test_iter\n",
    "    \n",
    "def create_model(hidden_dim, layers):\n",
    "    INPUT_DIM = len(review_parser.vocab)\n",
    "    EMBEDDING_DIM = 300\n",
    "    HIDDEN_DIM = hidden_dim\n",
    "    OUTPUT_DIM = 3 #5\n",
    "\n",
    "    model = SentimentAnalyzer(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, word_embeddings, layers=2)\n",
    "    attnModel = AttentionAnalyzer(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, word_embeddings, layers=2)\n",
    "    #model = RNN(32, 2, 256, len(review_parser.vocab), 300, word_embeddings)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    return model,attnModel\n",
    "\n",
    "def training_model(lr, epochs, model, train_iter, test_iter, BATCH_SIZE, HIDDEN_DIM, layers):\n",
    "    batch_size = BATCH_SIZE\n",
    "    output_size = 3\n",
    "    hidden_size = HIDDEN_DIM\n",
    "    embedding_length = 300\n",
    "    EPOCHS = 20\n",
    "    params = {'bs':BATCH_SIZE, 'hidden_dim':HIDDEN_DIM, 'lr':lr.item(), 'layers':layers}\n",
    "    #open file and check if trained, if so than return pretrained accuracy\n",
    "    try:\n",
    "        results = open(f\"Proj_results/Regular_{json.dumps(params)}\",\"r\")\n",
    "        data = json.loads(results.read())\n",
    "        print(f\"loaded for params:{params}\")\n",
    "        return max(data[\"test\"])\n",
    "    except: #the file does not exist i.e no model was trained with these parameters\n",
    "        nop = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    #train and return test best accuracy and average accuracy for baseline model\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    #RNN_train_loss_arr, RNN_train_acc_arr, RNN_val_loss_arr, RNN_val_acc_arr = \n",
    "    train_accur, test_accur = train_and_eval(model,train_iter, test_iter, optimizer, loss_fn=loss_fn, epochs=EPOCHS, verbose=False)\n",
    "    \n",
    "    results = open(f\"Proj_results/Regular_{json.dumps(params)}\", \"w\")\n",
    "    results.write(json.dumps({'params':params, 'train':train_accur, 'test':test_accur}))\n",
    "    results.close()\n",
    "    \n",
    "    return max(test_accur) #could check just last accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca5e28d6-c469-43bb-8307-12d0123f10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the hyperparameters range\n",
    "batches = [16,32] #batch sizes from 16 to 128 \n",
    "hiddens = [16,32,64] #list of possible hidden size (to model)\n",
    "layers = [i for i in range(1,2 + 1)] #layers from 1 to 3 (could add more)\n",
    "learning_rates = torch.logspace(-3,-4,3) #learning rates from 0.01 to 10^-6\n",
    "dropouts = [0,0.3,0.5]#torch.linspace(0,0.5,4) #dropout rate from 0 to 0.5\n",
    "epochs = 20#epochs will remain static\n",
    "\n",
    "file = open(\"results.txt\",\"w\")\n",
    "file.write(\"pending\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753695f-6110-405b-8407-c020c309f79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 1, \"lr\": 0.0010000000474974513, \"dropout\": 0}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 1, 'lr': 0.0010000000474974513, 'dropout': 0}, accur:0.6834821428571428\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**best:0.6834821428571428**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 1, \"lr\": 0.0003162277571391314, \"dropout\": 0}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 1, 'lr': 0.0003162277571391314, 'dropout': 0}, accur:0.6776785714285715\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 1, \"lr\": 9.999999747378752e-05, \"dropout\": 0}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 1, 'lr': 9.999999747378752e-05, 'dropout': 0}, accur:0.675\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 1, \"lr\": 0.0010000000474974513, \"dropout\": 0.3}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 1, 'lr': 0.0010000000474974513, 'dropout': 0.3}, accur:0.6816964285714285\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 1, \"lr\": 0.0003162277571391314, \"dropout\": 0.3}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 1, 'lr': 0.0003162277571391314, 'dropout': 0.3}, accur:0.6767857142857143\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 1, \"lr\": 9.999999747378752e-05, \"dropout\": 0.3}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 1, 'lr': 9.999999747378752e-05, 'dropout': 0.3}, accur:0.6754464285714286\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 1, \"lr\": 0.0010000000474974513, \"dropout\": 0.5}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 1, 'lr': 0.0010000000474974513, 'dropout': 0.5}, accur:0.6803571428571429\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 1, \"lr\": 0.0003162277571391314, \"dropout\": 0.5}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 1, 'lr': 0.0003162277571391314, 'dropout': 0.5}, accur:0.6839285714285714\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**best:0.6839285714285714**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 1, \"lr\": 9.999999747378752e-05, \"dropout\": 0.5}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 1, 'lr': 9.999999747378752e-05, 'dropout': 0.5}, accur:0.6696428571428571\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 2, \"lr\": 0.0010000000474974513, \"dropout\": 0}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 2, 'lr': 0.0010000000474974513, 'dropout': 0}, accur:0.6790178571428571\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 2, \"lr\": 0.0003162277571391314, \"dropout\": 0}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 2, 'lr': 0.0003162277571391314, 'dropout': 0}, accur:0.678125\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 2, \"lr\": 9.999999747378752e-05, \"dropout\": 0}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 2, 'lr': 9.999999747378752e-05, 'dropout': 0}, accur:0.6709821428571429\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 2, \"lr\": 0.0010000000474974513, \"dropout\": 0.3}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 2, 'lr': 0.0010000000474974513, 'dropout': 0.3}, accur:0.6799107142857143\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 2, \"lr\": 0.0003162277571391314, \"dropout\": 0.3}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 2, 'lr': 0.0003162277571391314, 'dropout': 0.3}, accur:0.6816964285714285\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 2, \"lr\": 9.999999747378752e-05, \"dropout\": 0.3}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 2, 'lr': 9.999999747378752e-05, 'dropout': 0.3}, accur:0.6674107142857143\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 2, \"lr\": 0.0010000000474974513, \"dropout\": 0.5}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 2, 'lr': 0.0010000000474974513, 'dropout': 0.5}, accur:0.6700892857142857\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 2, \"lr\": 0.0003162277571391314, \"dropout\": 0.5}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 2, 'lr': 0.0003162277571391314, 'dropout': 0.5}, accur:0.6785714285714286\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 16, \"num_layers\": 2, \"lr\": 9.999999747378752e-05, \"dropout\": 0.5}\n",
      "params:{'bs': 16, 'hidden_dim': 16, 'num_layers': 2, 'lr': 9.999999747378752e-05, 'dropout': 0.5}, accur:0.6638392857142857\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 32, \"num_layers\": 1, \"lr\": 0.0010000000474974513, \"dropout\": 0}\n",
      "params:{'bs': 16, 'hidden_dim': 32, 'num_layers': 1, 'lr': 0.0010000000474974513, 'dropout': 0}, accur:0.6736607142857143\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 32, \"num_layers\": 1, \"lr\": 0.0003162277571391314, \"dropout\": 0}\n",
      "params:{'bs': 16, 'hidden_dim': 32, 'num_layers': 1, 'lr': 0.0003162277571391314, 'dropout': 0}, accur:0.6803571428571429\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 32, \"num_layers\": 1, \"lr\": 9.999999747378752e-05, \"dropout\": 0}\n",
      "params:{'bs': 16, 'hidden_dim': 32, 'num_layers': 1, 'lr': 9.999999747378752e-05, 'dropout': 0}, accur:0.675\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 32, \"num_layers\": 1, \"lr\": 0.0010000000474974513, \"dropout\": 0.3}\n",
      "params:{'bs': 16, 'hidden_dim': 32, 'num_layers': 1, 'lr': 0.0010000000474974513, 'dropout': 0.3}, accur:0.6803571428571429\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 32, \"num_layers\": 1, \"lr\": 0.0003162277571391314, \"dropout\": 0.3}\n",
      "params:{'bs': 16, 'hidden_dim': 32, 'num_layers': 1, 'lr': 0.0003162277571391314, 'dropout': 0.3}, accur:0.6803571428571429\n",
      "training params:{\"bs\": 16, \"hidden_dim\": 32, \"num_layers\": 1, \"lr\": 9.999999747378752e-05, \"dropout\": 0.3}\n"
     ]
    }
   ],
   "source": [
    "train_iter, valid_iter, test_iter = create_dataset(32)\n",
    "from IPython.display import Markdown, display\n",
    "'''\n",
    "print(batches)\n",
    "print(hiddens)\n",
    "print(layers)\n",
    "print(learning_rates)\n",
    "'''\n",
    "\n",
    "best_params = None\n",
    "best_accur = 0\n",
    "for batch in batches:\n",
    "#batch size is fixed to 32 just for the moment\n",
    "    for h in hiddens:\n",
    "        for layer in layers:\n",
    "            for drop in dropouts:\n",
    "                for lr in learning_rates:\n",
    "                    params =  {'bs':batch, 'hidden_dim':h, 'num_layers':layer, 'lr':lr.item(), 'dropout':drop}\n",
    "                    _, attnModel = create_model(h, layer)\n",
    "                    attnModel = attnModel.to(device)\n",
    "                    print(f\"training params:{json.dumps(params)}\")\n",
    "                    accur = training_model(lr, epochs, attnModel, train_iter, test_iter, batch, h, layer)\n",
    "                    print(f'params:{params}, accur:{accur}')\n",
    "                    if accur > best_accur:\n",
    "                        display(Markdown(f'**best:{accur}**'))\n",
    "                        best_accur = accur\n",
    "                        best_params = params\n",
    "           \n",
    "file = open(\"results.txt\",\"w\")\n",
    "file.write(json.dumps(best_parameters))         \n",
    "file.close()\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427efdd-cc5e-45c7-bc1c-9541b2a1341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = os.listdir('Proj_results')\n",
    "best = 0\n",
    "best_params = {}\n",
    "for file_name in names:\n",
    "    file = open(file_name, 'r')\n",
    "    data = json.loads(file.read())\n",
    "    res = max(data['test'])\n",
    "    print(f'for params{json.dumps(data['params'])} got: {res} test accuracy)\n",
    "    if res > best:\n",
    "          best = res\n",
    "          best_params = data['params']\n",
    "          display(Markdown(f'**best:{accur}**'))\n",
    "    file.close()\n",
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
